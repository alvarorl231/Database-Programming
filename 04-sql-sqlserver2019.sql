-- COMMANDS
-- SQL 

-- INDEXES

-- CREATION: syntax
/*
CREATE [UNIQUE] [| NONCLUSTERED]
	INDEX index_name ON table (kolom [,...n])
*/
	CREATE UNIQUE INDEX test_index ON test(id); 
	-- unique: all values in the indexed column should be unique
	-- columns in a unique index should have the not null constraint


-- REMOVING INDEXES
	DROP INDEX test.test_index;
	-- DROP INDEX table_name.index


--1 index with several columns VS.several indexes with 1 column
use xtreme

create nonclustered index EmpLastName ON employee (lastname);
-- +
create nonclustered index EmpFirstname ON employee (firstname);
-- OR ?
create nonclustered index EmpLastNameFirstname ON employee(lastname, firstname);

-- So:
SELECT LASTNAME, FIRSTNAME
FROM EMPLOYEE;
-- does use the index with several columns,
-- and:
SELECT FIRSTNAME
FROM EMPLOYEE;
-- does use the index with 1 column
-- Conclusion: make your indexes according to the most commonly used queries.

-- Sort order with concatenated indexes
-- Index can be used in reverse order, but you can’t mix the order of the two fields.
CREATE NONCLUSTERED INDEX EmpLastnameTitle ON Employee (LastName ASC, Title ASC)


-- Rules of thumb

-- (1) Avoid use functions
-- BAD -> COST: 95%
SELECT EmployeeID, FirstName, LastName
FROM Employee
WHERE Year(BirthDate) = 1980;

-- GOOD -> COST: 5%
SELECT EmployeeID, FirstName, LastName
FROM Employee
WHERE BirthDate >= '1980-01-01'
AND BirthDate < '1981-01-01';

-- BAD -> COST: 94%
SELECT LastName
FROM Employee
WHERE substring (LastName, 1, 1) = 'D';
-- GOOD -> COST: 6%
SELECT LastName
FROM Employee
WHERE LastName like 'D%';


-- (2) Avoid calculations, isolate columns
-- BAD -> COST: 91%
SELECT EmployeeID, FirstName, LastName
FROM Employee
WHERE Salary*1.10 > 100000;

-- GOOD -> COST: 9%
SELECT EmployeeID, FirstName, LastName
FROM Employee
WHERE Salary > 100000/1.10;


-- (3) Prefer OUTER JOIN above UNION
-- BAD -> COST: 92%
SELECT lastname , firstname , orderid
FROM Employee e join Orders o ON e.EmployeeID = o.employeeid
UNION
SELECT lastname, firstname, null
FROM Employee
WHERE EmployeeID not in (SELECT EmployeeID FROM Orders);

-- GOOD -> COST: 8%
SELECT lastname , firstname , orderid
FROM Employee e left join Orders o ON e.EmployeeID = o.employeeid;

-- (4) Avoid ANY and ALL
-- BAD -> COST: 100%
SELECT lastname , firstname , birthdate
FROM Employee
WHERE BirthDate >= all (SELECT BirthDate FROM Employee);

-- GOOD -> COST: 0%
SELECT lastname , firstname , birthdate
FROM Employee
WHERE BirthDate = (SELECT max(BirthDate) FROM Employee);

-- (5) Index for equality first then for ranges.
select lastname, birthdate, country
from EmployeeHier
where BirthDate >= '1980-01-01' and BirthDate <= '1990-12-31'
and Country = 'Canada';

create index IdxCountryBirthdate on Employee (country, birthdate);

/* (6) Check the SQL code that is generated by your ORM tool or framework
• get to know how your ORM tool generates SQL queries
• e.g. Sometimes ORM tools use UPPER and LOWER without the
developer’s knowledge. Hibernate, for example, injects an implicit
LOWER for case insensitive searches*/

-- (7) Avoid dynamic SQL whenever possible
-- COST: 100%
declare @region varchar (10);
set @region = 'OR';
declare @sqlstring varchar (100) = 'select * from supplier where region=''' 
+ @region + '''';
exec (@sqlstring);
/*Disadvantages:
– no cached query execution plan -> slower
– debugging is more difficult (use PRINT!)
– Not allowed in UDF's (= risk of side effect)
– SQL injection*/


/*(8) Use bind variables
• Bind parameters also called dynamic parameters or bind variables
are an alternative way to pass data to the database.
• Instead of putting the values directly into the SQL statement, you just
use a placeholder like ?, :name or @name and provide the actual
values using a separate API call.
• Databases with an execution plan cache like SQL Server can reuse an
execution plan when executing the same statement multiple times. It
saves effort in rebuilding the execution plan but works only if the SQL
statement is exactly the same.*/


/*(9) Execute joins in the database.
• Don’t implement in your application what the database can do better
• Database is optimized for efficient data retrieval
• Limit network traffic*/

/*(10) Avoid unnecessary joins.
• Reading from many scattered tables is sensitive to disk seek latencies.
• JOIN can process only two tables at a time*/


-- Indexed views: schema binding
/*
• The indexed view must be schema bound to the tables referred to in the view to prevent
modifications of the table schema (frequently a major problem ).
• In SQL Server, views are not bound to the schema of the base tables by default. In such case
we may change the schema of the base table at any time, regardless of the fact that the
associated view may or may not work with the new schema. We can even drop the underlying
table while keeping the associated view without any warning. In this case when the view is
used, we will get an invalid object name error for the base table.
• If you want to create an index on a view or you want to preserve the base table schema once a
view has been defined, in both these cases you have to use the "WITH SCHEMABINDING"
clause to bind the view to the schema of the base tables:*/
CREATE VIEW dbo.V_ProductsCustomer(productcode, customername, sumquantity)
WITH SCHEMABINDING
AS SELECT productid, customername, sum(quantity)
FROM dbo.customer
JOIN dbo.orders ON orders.customerid = customer.customerid
JOIN dbo.ordersdetail ON orders.orderid = ordersdetail.orderid
GROUP BY productid, customername;

SELECT * FROM dbo.V_ProductsCustomer ORDER BY sumquantity desc;
/*
• Be aware that if you do not use the schema name, ( dbo ) in this case, then you will get the
following error while creating the view. "Cannot schema bind view ' dbo.vw_sampleView '
because name 'SAMPLETABLE' is invalid for schema binding. Names must be in two part
format and an object cannot reference itself.“
• So the steps are:
	1. Create view ( use schema name)
	2. Create clustered index on view
	3. Create any non clustered indexed on view*/


/* Partitioning
• Partition a table in different rowsets based on a column value , 
e.g. (but not restricted to ) a date related field.
• Assign each partition to a separate file or filegroup
• Older and rarely queried rows are separated from actual rows .
• Most queries need only actual rows  fewer rows have to be searched.
*/
USE StackOverflow2010;
-------------------------------------
-- Check for a useful partitioning 
-------------------------------------
select 
case when Score <= 0 then '1-low'
     when Score <= 1 then '2-low medium'
     when Score <= 3 then '3-high medium'
     else '4-high' end as category
,COUNT(*) count
from posts
group by 
case when Score <= 0 then '1-low'
     when Score <= 1 then '2-low medium'
     when Score <= 3 then '3-high medium'
     else '4-high' end;
----------------------------------------
-- CREATE A FILEGROUP FOR EACH PARTITION
----------------------------------------
ALTER DATABASE StackOverflow2010
ADD FILEGROUP test1fg;
GO
ALTER DATABASE StackOverflow2010
ADD FILEGROUP test2fg;
GO
ALTER DATABASE StackOverflow2010
ADD FILEGROUP test3fg;
GO
ALTER DATABASE StackOverflow2010
ADD FILEGROUP test4fg; 
----------------------------------------
-- ADD A DATAFILE TO EACH PARTITION
----------------------------------------
ALTER DATABASE StackOverflow2010 
ADD FILE 
(
    NAME = sof1,
    FILENAME = 'C:\Program Files\Microsoft SQL Server\MSSQL15.MSSQLSERVER\MSSQL\DATA\sof1.ndf',
    SIZE = 100MB,
    FILEGROWTH = 50MB
)
TO FILEGROUP test1fg;

ALTER DATABASE StackOverflow2010 
ADD FILE 
(
    NAME = sof2,
    FILENAME = 'C:\Program Files\Microsoft SQL Server\MSSQL15.MSSQLSERVER\MSSQL\DATA\sof2.ndf',
    SIZE = 100MB,
    FILEGROWTH = 50MB
)
TO FILEGROUP test2fg; 

ALTER DATABASE StackOverflow2010 
ADD FILE 
(
    NAME = sof3,
    FILENAME = 'C:\Program Files\Microsoft SQL Server\MSSQL15.MSSQLSERVER\MSSQL\DATA\sof3.ndf',
    SIZE = 100MB,
    FILEGROWTH = 50MB
)
TO FILEGROUP test3fg;

ALTER DATABASE StackOverflow2010 
ADD FILE 
(
    NAME = sof4,
    FILENAME = 'C:\Program Files\Microsoft SQL Server\MSSQL15.MSSQLSERVER\MSSQL\DATA\sof4.ndf',
    SIZE = 100MB,
    FILEGROWTH = 50MB
)
TO FILEGROUP test4fg;

/* For removing a file: first drop the tables and then: 
alter database stackoverflow2010 remove file sof1 (= logical name) */
---------------------------------------------------
-- Create a partition function called scorePF1 that 
-- will partition a table into four partitions
---------------------------------------------------
CREATE PARTITION FUNCTION scorePF1 (int /*data type of column used for partitioning*/)
    AS RANGE LEFT FOR VALUES (0, 1, 3) ;  -- 3 boundary values --> 4 partitions
	-- LEFT/RIGHT specifies to which side of the interval the boundary value belongs
GO
-----------------------------------------------------------------
-- Create a partition scheme called scorePF1 that 
-- applies function scorePF1 to the four filegroups created above
------------------------------------------------------------------
CREATE PARTITION SCHEME scorePF1
    AS PARTITION scorePF1
    TO (test1fg, test2fg, test3fg, test4fg) ;
GO
----------------------------------------------------------
-- Create a partitioned table called PartitionTable that 
--  uses scorePF1 to partition on score
----------------------------------------------------------
CREATE TABLE PostsPartitioned (
	id int not null, 
	body nvarchar(max) not null,
	creationdate datetime not null,
	score int not null, 
	title nvarchar(250), 
	CONSTRAINT posts_pk PRIMARY KEY (id,score)) -- partitioning column must be part of the primary key!
    ON scorePF1 (score);  
--------------------------------------------------
-- Populuate the table
-- (requires several gigabytes of free disk space)
--------------------------------------------------
insert into PostsPartitioned 
select Id,body,creationdate,score,title from Posts;  

-- check size of datafiles at C:\Program Files\Microsoft SQL Server\MSSQL15.MSSQLSERVER01\MSSQL\DATA\

-------------------------
-- SELECT FROM THE TABLE 
-------------------------
-- select from single partition
select score,COUNT(*)
from PostsPartitioned
where score <= 0
group by score;

-- select from multiple partitions --> slower
select score,COUNT(*)
from PostsPartitioned
where score >= 2
group by score;


-- MEOMRY OPTIMIZED TABLES
USE xtreme
----------------------------------
-- CONFIGURE RECOMMENDED DB OPTION
----------------------------------
ALTER DATABASE CURRENT SET MEMORY_OPTIMIZED_ELEVATE_TO_SNAPSHOT=ON 
GO 
-------------------------------------------------------------
-- CREATE A FILEGROUP AND DATAFILE FOR MEMORY OPTIMIZE TABLES
-------------------------------------------------------------
ALTER DATABASE xtreme
ADD FILEGROUP memoptfg CONTAINS MEMORY_OPTIMIZED_DATA
GO
ALTER DATABASE xtreme 
ADD FILE 
(
    NAME = memoptfile,
    FILENAME = 'C:\Program Files\Microsoft SQL Server\MSSQL15.MSSQLSERVER\MSSQL\DATA\memoptfile.ndf'
)
TO FILEGROUP memoptfg;
----------------------------------------
-- CREATE DURABLE MEMORY OPTIMIZED-TABLE
----------------------------------------
IF OBJECT_ID('dbo.table1') IS NOT NULL
	DROP TABLE dbo.table1

CREATE TABLE dbo.table1 
( c1 INT IDENTITY PRIMARY KEY NONCLUSTERED, c2 NVARCHAR(MAX)) 
WITH (MEMORY_OPTIMIZED=ON) 
GO 
--------------------------------------------
-- CREATE NON DURABLE MEMORY OPTIMIZED-TABLE
--------------------------------------------
IF OBJECT_ID('dbo.table1') IS NOT NULL
	DROP TABLE dbo.temp_table1

CREATE TABLE dbo.temp_table1 
( c1 INT IDENTITY PRIMARY KEY NONCLUSTERED, c2 NVARCHAR(MAX)) 
WITH (MEMORY_OPTIMIZED=ON, DURABILITY=SCHEMA_ONLY) 
GO
--------------
-- INSERT DATA
--------------
INSERT INTO table1 VALUES (N'sample durable') 
INSERT INTO temp_table1 (c2) VALUES (N'sample non-durable')

SELECT * FROM table1;
SELECT * FROM temp_table1;

-- Check what happens with both tables if you restart your database service

SELECT * FROM table1;
SELECT * FROM temp_table1;



